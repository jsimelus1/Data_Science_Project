{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from psycopg2 import sql\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from psycopg2.extensions import adapt, register_adapter, AsIs\n",
    "from sqlalchemy import create_engine, text\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tenure_by_Plumbing.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the file paths\n",
    "file_paths = ['2018_Tenure_by_Plumbing.csv', \n",
    "              '2019_Tenure_by_Plumbing.csv',\n",
    "              '2020_Tenure_by_Plumbing.csv', \n",
    "              '2021_Tenure_by_Plumbing.csv', \n",
    "              '2022_Tenure_by_Plumbing.csv']\n",
    "\n",
    "# Reading the data files into dataframes\n",
    "dataframes = [pd.read_csv(file) for file in file_paths]\n",
    "\n",
    "# Concatenate all the dataframes into one\n",
    "Tenure_by_Plumbing = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Save the merged dataframe to a new CSV file\n",
    "merged_file_path = 'Tenure_by_Plumbing.csv'\n",
    "Tenure_by_Plumbing.to_csv(merged_file_path, index=False)\n",
    "\n",
    "# Provide the path of the merged file\n",
    "merged_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type username (pawprint) and hit enter: jsmm8\n",
      "Type password and hit enter: ········\n"
     ]
    }
   ],
   "source": [
    "database = \"f24t03\"\n",
    "user     = input(\"Type username (pawprint) and hit enter: \")\n",
    "password = getpass.getpass(\"Type password and hit enter: \")\n",
    "\n",
    "connection = psycopg2.connect(database = database,\n",
    "                              user     = user,\n",
    "                              host     = 'pgsql',\n",
    "                              password = password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with connection, connection.cursor() as cursor:\n",
    "    cursor.execute(\"DROP TABLE IF EXISTS tenure_by_plumbing;\")\n",
    "    \n",
    "\n",
    "    cursor.execute(\n",
    "        '''\n",
    "        CREATE TABLE IF NOT EXISTS tenure_by_plumbing (\n",
    "    geo_id TEXT,\n",
    "    block_group TEXT,\n",
    "    census_tract TEXT,\n",
    "    county TEXT,\n",
    "    state TEXT,\n",
    "    est_total NUMERIC,\n",
    "    moe_total NUMERIC,\n",
    "    est_own_occ NUMERIC,\n",
    "    moe_own_occ NUMERIC,\n",
    "    est_own_occ_plumb_complete NUMERIC,\n",
    "    moe_own_occ_plumb_complete NUMERIC,\n",
    "    est_own_occ_plumb_lack NUMERIC,\n",
    "    moe_own_occ_plumb_lack NUMERIC,\n",
    "    est_rent_occ NUMERIC,\n",
    "    moe_rent_occ NUMERIC,\n",
    "    est_rent_occ_plumb_complete NUMERIC,\n",
    "    moe_rent_occ_plumb_complete NUMERIC,\n",
    "    est_rent_occ_plumb_lack NUMERIC,\n",
    "    moe_rent_occ_plumb_lack NUMERIC,\n",
    "    year INT,\n",
    "    PRIMARY KEY (geo_id, year)\n",
    "    );\n",
    "    '''\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your database password: ········\n",
      "Database connection established successfully.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 500 records to the database.\n",
      "Uploaded a chunk of 105 records to the database.\n",
      "CSV data uploaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Securely getting the password\n",
    "mypasswd = getpass.getpass(\"Enter your database password: \")\n",
    "\n",
    "# Database connection parameters\n",
    "username = 'jsmm8'\n",
    "host = 'pgsql'\n",
    "database = 'f24t03'\n",
    "\n",
    "# Constructing the connection string\n",
    "conn_string = f\"postgresql+psycopg2://{username}:{mypasswd}@{host}/{database}\"\n",
    "\n",
    "# Create the SQLAlchemy engine\n",
    "try:\n",
    "    engine = create_engine(conn_string)\n",
    "    print(\"Database connection established successfully.\")\n",
    "except Exception as conn_err:\n",
    "    print(f\"Database connection error: {conn_err}\")\n",
    "\n",
    "# CSV file to be imported\n",
    "tenure_by_plumbing = 'Tenure_by_Plumbing.csv'\n",
    "\n",
    "# Chunk size for batch import\n",
    "chunk_size = 500\n",
    "\n",
    "try:\n",
    "    # Reading and uploading the CSV in chunks\n",
    "    for chunk in pd.read_csv(tenure_by_plumbing, chunksize=chunk_size):\n",
    "        # Load the data to PostgreSQL (append data in chunks)\n",
    "        chunk.to_sql('tenure_by_plumbing', engine, if_exists='append', index=False)\n",
    "        print(f\"Uploaded a chunk of {len(chunk)} records to the database.\")\n",
    "    \n",
    "    print(\"CSV data uploaded successfully.\")\n",
    "\n",
    "except pd.errors.EmptyDataError:\n",
    "    print(\"The CSV file is empty. Please check the file contents.\")\n",
    "except pd.errors.ParserError as parse_err:\n",
    "    print(f\"Error parsing CSV file: {parse_err}\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Privileges granted successfully.\n"
     ]
    }
   ],
   "source": [
    "# SQL query to grant privileges\n",
    "grant_privileges_query = \"GRANT ALL PRIVILEGES ON TABLE tenure_by_plumbing TO ypd5yb, remcmf, sgdky;\"\n",
    "\n",
    "with engine.connect() as connection:\n",
    "        connection.execute(text(grant_privileges_query))\n",
    "        print(\"Privileges granted successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully.\n"
     ]
    }
   ],
   "source": [
    "select_query = \"SELECT * FROM tenure_by_plumbing WHERE year = 2022 LIMIT 10;\" \n",
    "\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(text(select_query))\n",
    "    df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "df\n",
    "print(\"Query executed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query executed successfully.\n"
     ]
    }
   ],
   "source": [
    "select_query = \"SELECT * FROM tenure_by_plumbing WHERE year = 2018 LIMIT 10;\" \n",
    "\n",
    "with engine.connect() as connection:\n",
    "    result = connection.execute(text(select_query))\n",
    "    df = pd.DataFrame(result.fetchall(), columns=result.keys())\n",
    "df\n",
    "print(\"Query executed successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
